{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Roman;\f1\froman\fcharset0 Times-Bold;\f2\fnil\fcharset134 STSongti-SC-Bold;
\f3\fnil\fcharset134 STSongti-SC-Regular;\f4\froman\fcharset0 Times-Italic;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue11;\red0\green0\blue233;
\red251\green0\blue7;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c0;\cssrgb\c0\c0\c93333;
\cssrgb\c100000\c0\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid201\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}}
{\info
{\doccomm Academic website for Junwei Liang. Mina Mahbub Hossain is currently a tenure-track Assistant Professor at The Hong Kong University of Science and Technology (Guangzhou). He is also an affiliate assistant professor at HKUST computer science & engineering department. He was a senior researcher at Tencent Youtu Lab working on cutting-edge computer vision research and applications. Prior to that, he received his Ph.D. degree from Carnegie Mellon University, working with Prof. Alexander Hauptmann. He is the recipient of Baidu Scholarship and Yahoo Fellowship, and awarded Rising Star Award at the World AI Conference in 2020. He is the winner of several public safety video analysis competitions, including ASAPS and TRECVID ActEV. His work has helped and been reported by major news agencies like the Washington Post and New York Times. His research interests include human trajectory forecasting, action recognition, and large-scale computer vision and video analytics in general. His mission: develop AI technologies for social good.}
{\keywords Junwei Liang, CMU, HKUST, HKUST-GZ, Professor, computer vision, PhD, \uc0\u26753 \u20426 \u21355 , Carnegie Mellon University, The Hong Kong University of Science and Technology}}\margl1440\margr1440\vieww34360\viewh19060\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬} \
\pard\pardeftab720\sa298\partightenfactor0

\f1\b\fs36 \cf0 Mina Mahbub Hossain\

\f2 \'c1\'ba\'bf\'a1\'ce\'c0
\f1 \
mahbub.hossain@usu.edu\
Utah State University\
Office: E4-304\
\pard\pardeftab720\sa298\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?hl=en&user=bMedjfUAAAAJ"}}{\fldrslt 
\fs28 \cf3 \ul \ulc3 \strokec3 Google Scholar}}\
\pard\pardeftab720\sa298\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://www.semanticscholar.org/author/Junwei-Liang/1915796"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [Semantic Scholar]}} {\field{\*\fldinst{HYPERLINK "https://www.researchgate.net/profile/Junwei_Liang3"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [Research Gate]}}\
\pard\pardeftab720\sa298\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/JunweiLiang"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [Github]}} {\field{\*\fldinst{HYPERLINK "https://www.linkedin.com/in/junweiliang/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [LinkedIn]}} {\field{\*\fldinst{HYPERLINK "https://www.youtube.com/channel/UC-z7ZWp8Rbu2xhxnbAL_bRQ"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [Youtube]}}\
{\field{\*\fldinst{HYPERLINK "https://www.zhihu.com/people/junwei-liang-50"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [
\f2 \'d6\'aa\'ba\'f5
\f1 ]}} {\field{\*\fldinst{HYPERLINK "https://www.xiaohongshu.com/user/profile/62c3a783000000001b02b099"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [
\f2 \'d0\'a1\'ba\'ec\'ca\'e9
\f1 ]}} {\field{\*\fldinst{HYPERLINK "https://twitter.com/JunweilLiang"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 [Twitter]}}\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/index.html"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 About }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/projects.html#projects"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Projects }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/projects.html#publications"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Publications }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/teaching.html#teaching"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Teaching / Talks }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/index.html#awards"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Honors / Awards }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/index.html#media"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Selected Media }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/awesome.html"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Awesome Lists }}{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/letter.html"}}{\fldrslt 
\f0\b0\fs24 \cf4 \ul \ulc4 \strokec4 \'a0 Letter}}
\f0\b0\fs24 \
\cf4 \ul \ulc4 \strokec4 Bio\cf0 \ulnone \strokec2  {{\NeXTGraphic badge.svg \width1760 \height400 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
I am an assistant professor at {\field{\*\fldinst{HYPERLINK "https://hkust-gz.edu.cn/academics/four-hubs/information-hub/artificial-intelligence"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 The Hong Kong University of Science and Technology (Guangzhou campus)}} in the AI Thrust. I am also an {\field{\*\fldinst{HYPERLINK "https://cse.hkust.edu.hk/admin/people/faculty/?c=affiliate_gz"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 affiliate assistant professor}} at HKUST computer science & engineering department. I am interested in building AI systems that can understand and predict human behaviors. Please see {\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/projects.html"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 these projects}} for an overview. 
\f1\b My mission: develop AI technologies for social good.
\f0\b0 \
\
Prior to joining HKUST-GZ, I was a senior researcher at Tencent Youtu Lab working with {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=Ljk2BvIAAAAJ&hl=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Chunhua Shen}}, where we landed commercial AI products in tens-of-millions-RMB-scale projects. I previously graduated from Carnegie Mellon University, where I was advised by {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=Py54GcEAAAAJ&hl=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Alexander Hauptmann}}. My Ph.D. and research work were mostly funded by {\field{\*\fldinst{HYPERLINK "https://www.iarpa.gov/research-programs/diva"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 IARPA}}, {\field{\*\fldinst{HYPERLINK "https://www.nist.gov/ctl/pscr/real-time-video-analytics-situation-awareness"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 NIST}} and {\field{\*\fldinst{HYPERLINK "https://nsf.gov/awardsearch/showAward?AWD_ID=1650994&HistoricalAwards=false"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 NSF}} grants. I was a research intern at Google AI multiple times and collaborated with {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=jIKjjSYAAAAJ&hl=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Lu Jiang}}, {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=S-hBSfIAAAAJ&hl=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Liangliang Cao}}, {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=feX1fWAAAAAJ"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Jia Li}} and {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=MxxZkEcAAAAJ&hl=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Kevin Murphy}}. I obtained my undergraduate degree from {\field{\*\fldinst{HYPERLINK "https://www.ruc.edu.cn/en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 RUC}}, advised by {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=8UkYbCMAAAAJ&hl=zh-CN"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Qin Jin}}.\
\cf4 \ul \ulc4 \strokec4 Research Group\cf0 \ulnone \strokec2  (Lab website: {\field{\*\fldinst{HYPERLINK "https://precognition.team/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 precognition.team}})\
Our group, the Precognition Lab (
\f3 \'d6\'c7\'c4\'dc\'b8\'d0\'d6\'aa\'d3\'eb\'d4\'a4\'b2\'e2\'d1\'d0\'be\'bf\'d7\'e9
\f0 ), is interested in building human-level AI systems. We focus on machine perception of human activities and the world, jointly with machine prediction of unseen future states. We believe in order to enable machines to understand and behave like humans, we should build world models with common sense knowledge that could aid intelligent agents in making action decisions. As a first step, sequential data (like that of videos) perception and prediction are important research topics to tackle.\
\
\pard\pardeftab720\partightenfactor0
\cf5 \strokec5 I have multiple \strike \strikec5 fully-funded Ph.D.\strike0\striked0  and research assistant/intern positions available.\cf0 \strokec2  Please checkout potential {\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/projects.html"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 projects}} and {\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/letter.html"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 this letter}} if you are interested in joining our group. 
\f3 \'d5\'d0\'c9\'fa\'ce\'c4
\f0 : [{\field{\*\fldinst{HYPERLINK "https://zhuanlan.zhihu.com/p/562523740"}}{\fldrslt 
\f3 \cf4 \ul \ulc4 \strokec4 \'d6\'aa\'ba\'f5}}] [{\field{\*\fldinst{HYPERLINK "https://www.xiaohongshu.com/discovery/item/6323ed9e00000000110142ad"}}{\fldrslt 
\f3 \cf4 \ul \ulc4 \strokec4 \'d0\'a1\'ba\'ec\'ca\'e9}}]\
\
For fellow assistant professors and Ph.D. students, I have gathered some awesome lists of resources that may be useful for your success. See {\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/awesome.html"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 here}} and feel free to contribute on Github. If you want to meet, check out {\field{\*\fldinst{HYPERLINK "https://calendar.google.com/calendar/embed?src=junweiliang1114%40gmail.com&ctz=Asia%2FShanghai"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 my public calendar}} first and propose a meeting via email.\
\pard\pardeftab720\partightenfactor0
\cf4 \ul \ulc4 \strokec4 News\cf0 \ulnone \strokec2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 06/2023 The Precognition Workshop was successfully held at CVPR! Thanks to all the co-organizers and program committee members! [{\field{\*\fldinst{HYPERLINK "https://sites.google.com/view/ieeecvf-cvpr2023-precognition"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Workshop Site}}] [{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=Z3JhfOp0eGM"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 CVPR Workshop Recording}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 02/2023 One paper accepted by 
\f1\b CVPR 2023
\f0\b0 . Congrats to Xiaoyu!\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 02/2023 I'm teaching {\field{\*\fldinst{HYPERLINK "https://hkust-aiaa5032.github.io/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 AIAA 5032 Foundations of Artificial Intelligence}} and {\field{\*\fldinst{HYPERLINK "https://hkust-aiaa5036.github.io/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 AIAA 5036 Autonomous AI}} this semester at HKUST (Guangzhou).\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 01/2023 I am co-organizing the {\field{\*\fldinst{HYPERLINK "https://sites.google.com/view/ieeecvf-cvpr2023-precognition"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 The 5th workshop on Precognition: Seeing through the Future}} @CVPR 2023. [{\field{\*\fldinst{HYPERLINK "https://www.linkedin.com/posts/junweiliang_cvpr2023-workshop-computervision-activity-7030466054787121152-NacF?utm_source=share&utm_medium=member_desktop"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Call For Papers}}] [{\field{\*\fldinst{HYPERLINK "https://zhuanlan.zhihu.com/p/603134088"}}{\fldrslt 
\f3 \cf4 \ul \ulc4 \strokec4 \'d6\'aa\'ba\'f5}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 10/2022 Presented first-ever lecture at HKUST (Guangzhou). [{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=i2M9codDGes"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 AI Seminar}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 10/2022 
\f1\b Two
\f0\b0  papers accepted at 
\f1\b NeurIPS 2022
\f0\b0 . [{\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2209.12362"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Multi-Action}} ({\field{\*\fldinst{HYPERLINK "https://nips.cc/virtual/2022/spotlight/65262"}}{\fldrslt \cf5 \ul \ulc5 \strokec5 Spotlight paper}}, 3.7% acceptance rate, 384/10411)] [{\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2209.13307"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Video Retrieval}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 10/2022 Joined HKUST-GZ as a Tenure-Track Assistant Professor. Started an {\field{\*\fldinst{HYPERLINK "https://github.com/JunweiLiang/awesome_lists"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 awesome list}} collection for TTAPs and PhD students.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 09/2022 Invited to present at a young researcher forum by {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=qpBtpGsAAAAJ&hl=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Prof. Xiaoou Tang}} and {\field{\*\fldinst{HYPERLINK "https://www.shlab.org.cn/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Shanghai AI Lab}}.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 06/2022 Achieved 
\f1\b second-place
\f0\b0  out of 150 teams on the {\field{\*\fldinst{HYPERLINK "https://arxiv.org/pdf/2204.10380.pdf"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 public leaderboard}} of the Naturalist Driver Action Recognition Task - AI City Challenge @ CVPR 2022. [{\field{\*\fldinst{HYPERLINK "https://openaccess.thecvf.com/content/CVPR2022W/AICity/papers/Liang_Stargazer_A_Transformer-Based_Driver_Action_Detection_System_for_Intelligent_Transportation_CVPRW_2022_paper.pdf"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 CVPRW Paper}}] [{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=u4CrNKt4P54"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Presentation}}] [{\field{\*\fldinst{HYPERLINK "https://github.com/JunweiLiang/aicity_action"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Code and Model}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 10/2021 Published a {\field{\*\fldinst{HYPERLINK "https://www.techbeat.net/talk-info?id=588"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 research talk}} at TechBeat.net on Pedestrian Trajectory Prediction. [{\field{\*\fldinst{HYPERLINK "https://www.techbeat.net/talk-info?id=588"}}{\fldrslt 
\f3 \cf4 \ul \ulc4 \strokec4 \'bd\'ab\'c3\'c5
\f0 TechBeat}}] [{\field{\*\fldinst{HYPERLINK "https://www.bilibili.com/video/BV1Y44y1x7nv/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 B
\f3 \'d5\'be}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 08/2021 Received Doctoral Consortium Award at ICCV 2021, mentored by {\field{\*\fldinst{HYPERLINK "https://people.epfl.ch/alexandre.alahi?lang=en"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Prof. Alexandre Alahi}}.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 08/2021 1 paper accepted by 
\f1\b ICCV 2021
\f0\b0 .\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 08/2021 Our {\field{\*\fldinst{HYPERLINK "https://vera.cs.cmu.edu/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 VERA}} system helps another major 
\f1\b Washington Post
\f0\b0  news report. [{\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/world/interactive/2021/myanmar-crackdown-military-coup/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 link}}] {\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/world/interactive/2021/myanmar-crackdown-military-coup/"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}}}\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 07/2021 Successfully defended my Ph.D. thesis: From Recognition to Prediction: Analysis of Human Action and Trajectory Prediction in Video. [{\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/thesis/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 link}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 04/2021 Featured in a {\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/investigations/interactive/2021/dc-police-records-capitol-riot/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 front-page news report}} (04/15) by Washington Post using crowding counting technologies. [{\field{\*\fldinst{HYPERLINK "https://www.youtube.com/watch?v=rsQTY9083r8?t=1086"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 video}}] [{\field{\*\fldinst{HYPERLINK "https://www.zhihu.com/zvideo/1366151651770834944"}}{\fldrslt 
\f3 \cf4 \ul \ulc4 \strokec4 \'d6\'aa\'ba\'f5}}] {\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/investigations/interactive/2021/dc-police-records-capitol-riot/"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}}}\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 01/2021 
\f1\b Invited presentation
\f0\b0  at ICPR'20 pattern forecasting workshop. [{\field{\*\fldinst{HYPERLINK "https://sites.google.com/di.uniroma1.it/patcast/program?authuser=0"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 link}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 09/2020 We won the {\field{\*\fldinst{HYPERLINK "https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2020-automated-stream-analysis"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Automated Streams Analysis for Public Safety Challenge}} with a {\field{\*\fldinst{HYPERLINK "https://www.herox.com/ASAPS1/update/3483"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 $30k prize}}.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 08/2020 Our {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2006.16479"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 paper}} has been accepted by WACV 2021 (one strong-accept) and 
\f1\b reported by CMU news
\f0\b0 : {\field{\*\fldinst{HYPERLINK "https://www.cmu.edu/news/stories/archives/2020/august/drones-hurricane-damage.html"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}}}\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 08/2020 Analyzed videos for journalist from 
\f1\b the Washington Post
\f0\b0  on a {\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/sports/2020/08/26/redskins-cheerleaders-video-daniel-snyder-washington/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 major news}}. {\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/sports/2020/08/26/redskins-cheerleaders-video-daniel-snyder-washington/"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}}}\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 07/2020 Awarded {\field{\*\fldinst{HYPERLINK "https://baijiahao.baidu.com/s?id=1671984902144018200&wfr=spider&for=pc"}}{\fldrslt 
\f4\i \cf4 \ul \ulc4 \strokec4 "AI Rising Star"}} at the {\field{\*\fldinst{HYPERLINK "https://worldaic.com.cn/portal/en/index.html"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 World AI Conference}}.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 07/2020 {\field{\*\fldinst{HYPERLINK "https://precognition.team/next/simaug/"}}{\fldrslt 
\f4\i \cf4 \ul \ulc4 \strokec4 SimAug}} paper accepted by 
\f1\b ECCV 2020
\f0\b0 .\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 06/2020 {\field{\*\fldinst{HYPERLINK "https://precognition.team/next/multiverse/index.html"}}{\fldrslt 
\f4\i \cf4 \ul \ulc4 \strokec4 Multiverse}} (
\f1\b CVPR 2020
\f0\b0 ) code and dataset are released! [{\field{\*\fldinst{HYPERLINK "https://medium.com/@junweil/cvpr20-the-garden-of-forking-paths-towards-multi-future-trajectory-prediction-df23221dc9f8"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 blog}}] [{\field{\*\fldinst{HYPERLINK "https://zhuanlan.zhihu.com/p/148343447"}}{\fldrslt 
\f3 \cf4 \ul \ulc4 \strokec4 \'d6\'aa\'ba\'f5}}] [{\field{\*\fldinst{HYPERLINK "https://github.com/JunweiLiang/Multiverse"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 code}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 12/2019 Received {\field{\*\fldinst{HYPERLINK "http://scholarship.baidu.com/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Baidu Scholarship}} (10 recipients globally). Press Coverage: {\field{\*\fldinst{HYPERLINK "http://news.ruc.edu.cn/archives/267603"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "http://m.china.com.cn/appshare/doc_1_20_1489589.html?from=groupmessage&isappinstalled=0"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://baijiahao.baidu.com/s?id=1654884571460145099&wfr=spider&for=pc"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://www.yanxishe.com/blogDetail/17504"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "http://app.bjheadline.com/8816/newshow.php?newsid=5514954&src=stream&typeid=20&uid=335186&did=16835adeb9fa457b8ec1f9b570dcc4b1&show=0&fSize=M&ver=2.6.3&ff=fz&mood=wx&from=groupmessage&isappinstalled=0"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}}}\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 09/2019 Our {\field{\*\fldinst{HYPERLINK "https://vera.cs.cmu.edu/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Shooter Localization System}} won 
\f1\b Best Demo
\f0\b0  award at {\field{\*\fldinst{HYPERLINK "https://cbmi2019.org/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 CBMI2019}}. [{\field{\*\fldinst{HYPERLINK "https://vera.cs.cmu.edu/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Project Site}}] \uc0\u8232 Press Coverage: {\field{\*\fldinst{HYPERLINK "https://www.cmu.edu/news/stories/archives/2019/november/system-locates-shooters-using-smartphone-video.html"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://pittsburgh.cbslocal.com/2019/11/20/cmu-develops-video-system-locate-mass-shooters/"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://www.post-gazette.com/business/tech-news/2019/11/20/Carnegie-Mellon-CMU-develops-cellphone-smartphone-video-system-location-shooter-triangulate/stories/201911200101"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://gizmodo.com/smartphone-videos-can-now-be-analyzed-and-used-to-pinpo-1839979803"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://www.dailymail.co.uk/sciencetech/article-7707501/Carnegie-Mellon-aims-end-pro-longed-massacres-locates-active-shooters.html"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\ul  }}, {\field{\*\fldinst{HYPERLINK "https://www.techspot.com/news/82881-researchers-develop-system-can-pinpoint-shooter-location-using.html"}}{\fldrslt \cf4 \strokec4 {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}}}\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 06/2019 Presented Future Prediction paper at 
\f1\b CVPR 2019
\f0\b0 . It was reported by the media and it received 
\f1\b 30k+ views
\f0\b0  in a week. [{\field{\*\fldinst{HYPERLINK "https://twitter.com/jcniebles/status/1141366303921303552"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Tweets}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 04/2019 Our CMU team's (INF & MUDSML) system achieved the 
\f1\b best performance
\f0\b0  on the {\field{\*\fldinst{HYPERLINK "https://actev.nist.gov/prizechallenge#tab_leaderboard"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 activity detection challenge}} ({\field{\*\fldinst{HYPERLINK "file:///Users/hossainmm/website_mina/mina-mahbub.github.io/resources/actev-prizechallenge-06-2019.png"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Cached}}) in surveillance videos hosted by NIST & IARPA. We have released our code and model for Object Detection & Tracking {\field{\*\fldinst{HYPERLINK "https://github.com/JunweiLiang/Object_Detection_Tracking"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 here}}.\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 12/2018 
\f1\b MemexQA
\f0\b0  paper accepted by 
\f1\b TPAMI 2019
\f0\b0 .\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 06/2018 Presented MemexQA paper at 
\f1\b CVPR 2018
\f0\b0 . [{\field{\*\fldinst{HYPERLINK "https://youtu.be/TBOnKekODCI?t=1h11m29s"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Spotlight Talk}}]\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 11/2016 
\f1\b Best performer
\f0\b0  in the NIST TRECVID 2016 Ad-hoc Video Search Challenge (no annotation track).\
\pard\pardeftab720\partightenfactor0
\cf4 \ul \ulc4 \strokec4 Awards\cf0 \ulnone \strokec2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 ICCV Doctoral Consortium Award 2021\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0
\f4\i \cf4 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://baijiahao.baidu.com/s?id=1671984902144018200&wfr=spider&for=pc"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec4 Rising Star}}
\f0\i0 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2  (
\f3 \'d4\'c6\'b7\'ab\'bd\'b1
\f0 -
\f3 \'c3\'f7\'c8\'d5\'d6\'ae\'d0\'c7
\f0 ), World AI Conference 2020\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Baidu Scholarship (10 Ph.D. students worldwide) 2019\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Winner, {\field{\*\fldinst{HYPERLINK "https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2020-automated-stream-analysis"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Automated Streams Analysis for Public Safety Challenge}} - $30k prize 2020\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Best Demo Award at CBMI2019 2019\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Yahoo! Fellowship 2016 - 2018\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Winner, TRECVID ActEV Challenge 2019\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Winner, TRECVID Ad-hoc Video Search Challenge, no annotation track 2016\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CMU LTI Student Research Symposium Best Paper Honorable Mentions 2018\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Google Cloud COVID-19 Research Grant - $6200 2020\
\pard\pardeftab720\partightenfactor0
\cf4 \ul \ulc4 \strokec4 Selected Media\cf0 \ulnone \strokec2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f1\b \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Washington Post.
\f0\b0  
\f4\i How Shireen Abu Akleh was killed
\f0\i0  (provided gunshot and shooter analysis), June 2022. [{\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/investigations/interactive/2022/shireen-abu-akleh-death/?itid=lk_inline_manual_4/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Link}}]\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Washington Post.
\f0\b0  
\f4\i Anatomy of a crackdown
\f0\i0  (provided gunshot and shooter analysis), August 25, 2021. [{\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/world/interactive/2021/myanmar-crackdown-military-coup//"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Link}}]\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Washington Post.
\f0\b0  
\f4\i 17 requests for backup in 78 minutes
\f0\i0  (provided crowd counting analysis), April 15, 2021. [{\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/investigations/interactive/2021/dc-police-records-capitol-riot/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Link}}]\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Carnegie Mellon University News.
\f0\b0  
\f4\i Amateur Drone Videos Could Aid in Natural Disaster Damage Assessment
\f0\i0 , August 28, 2020.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 AZO Robotics.
\f0\b0  
\f4\i New AI System Helps Detect Damage Caused to Buildings by Hurricanes
\f0\i0 , August 31, 2020.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Washington Post.
\f0\b0  
\f4\i Lewd cheerleader videos, sexist rules: Ex-employees decry Washington\'92s NFL team workplace
\f0\i0  (featured in the video analytics), August 26, 2020. [{\field{\*\fldinst{HYPERLINK "https://www.washingtonpost.com/sports/2020/08/26/redskins-cheerleaders-video-daniel-snyder-washington/"}}{\fldrslt \cf4 \ul \ulc4 \strokec4 Link}}]\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 CBS.
\f0\b0  
\f4\i Researchers At Carnegie Mellon University Develop Video System To Locate Mass Shooters Using Smartphones
\f0\i0 , November 20, 2019.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 post-gazette.
\f0\b0  
\f4\i CMU develops video system that can locate mass shooter
\f0\i0 , November 20, 2019.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 GIZMODO.
\f0\b0  
\f4\i Smartphone Videos Can Now Be Analyzed and Used to Pinpoint the Location of a Shooter
\f0\i0 , November 21, 2019.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 DailyMail.
\f0\b0  
\f4\i Active shooters can be located within minutes by new software that analyzes smartphone video from the scene and can even identify the type of gun
\f0\i0 , November 20, 2019.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Techspot.
\f0\b0  
\f4\i Researchers develop system that can pinpoint a shooter's location using smartphone videos
\f0\i0 , November 21, 2019.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 New York Times.
\f0\b0  
\f4\i Who Killed the Kiev Protesters? A 3-D Model Holds the Clues
\f0\i0  (featured in the video analytics), May 30, 2018.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \'b6\'c1\'d0\'be\'ca\'f5
\f1 .
\f0\b0  
\f3 \'bf\'a8\'c4\'da\'bb\'f9\'c3\'b7\'c2\'a1\'b4\'f3\'d1\'a7\'c1\'ba\'bf\'a1\'ce\'c0\'a3\'ba\'ca\'d3\'c6\'b5\'d6\'d0\'d0\'d0\'c8\'cb\'b5\'c4\'b6\'e0\'d6\'d6\'ce\'b4\'c0\'b4\'b9\'ec\'bc\'a3\'d4\'a4\'b2\'e2
\f0 , August, 2020.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Baidu.
\f0\b0  
\f3 \'b3\'cb\'b7\'e7\'c6\'c6\'c0\'cb\'b5\'c4
\f4\i AI
\f3\i0 \'bc\'bc\'ca\'f5\'c7\'e0\'c4\'ea
\f4\i \'97\'97
\f3\i0 \'ca\'d7\'bd\'ec
\f4\i WAIC
\f3\i0 \'d4\'c6\'b7\'ab\'bd\'b1\'c3\'fb\'b5\'a5\'b9\'ab\'b2\'bc
\f0 , July 11, 2020.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 China.com.cn.
\f0\b0  
\f3 \'c8\'cb\'b4\'f3\'b8\'df\'ea\'b2\'c8\'cb\'b9\'a4\'d6\'c7\'c4\'dc\'d1\'a7\'d4\'ba
\f4\i \'93
\f3\i0 \'b8\'df\'ce\'dd\'bd\'a8\'ea\'b2
\f4\i -
\f3\i0 \'c7\'e0\'c4\'ea\'cb\'b5
\f4\i \'94
\f3\i0 \'ca\'d7\'c6\'da\'bf\'aa\'bd\'b2
\f0 , Jan 6, 2020.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Baidu.
\f0\b0  
\f4\i AI
\f3\i0 \'bd\'e7\'b5\'c4\'d6\'d0\'b9\'fa\'c1\'a6\'c1\'bf\'a3\'a1\'b0\'d9\'b6\'c8\'bd\'b1\'d1\'a7\'bd\'f0\'d6\'fa\'c1\'a6\'d6\'d0\'b9\'fa
\f4\i AI
\f3\i0 \'c8\'cb\'b2\'c5\'d5\'c0\'b7\'c5\'b9\'e2\'c3\'a2\'a3\'a1
\f0 , Jan 5, 2020.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \'c1\'bf\'d7\'d3\'ce\'bb
\f1 .
\f0\b0  
\f3 \'c0\'ee\'b7\'c9\'b7\'c9\'cd\'c5\'b6\'d3\'d4\'ec\'b3\'f6
\f4\i \'94
\f3\i0 \'bf\'fa\'ca\'d3\'ce\'b4\'c0\'b4
\f4\i \'94
\f3\i0 \'d0\'c2
\f4\i AI:
\f3\i0 \'c8\'a5\'c4\'c4\'b8\'c9\'c9\'b6\'d2\'bb\'c6\'f0\'b2\'c2
\f4\i , 
\f3\i0 \'d7\'bc\'c8\'b7\'c2\'ca\'d1\'b9\'b5\'b9\'c0\'cf\'c7\'b0\'b1\'b2
\f0 , received 30k+ views in a week, Feb 13, 2019.\
\ls3\ilvl0
\f1\b \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}
\f2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \'bb\'fa\'c6\'f7\'d6\'ae\'d0\'c4
\f1 .
\f0\b0  
\f3 \'d3\'f6\'bc\'fb\'ce\'b4\'c0\'b4\'a3\'a1\'c0\'ee\'b7\'c9\'b7\'c9\'b5\'c8\'cc\'e1\'b3\'f6\'b6\'cb\'b5\'bd\'b6\'cb\'cf\'b5\'cd\'b3
\f4\i Next
\f3\i0 \'d4\'a4\'b2\'e2\'ce\'b4\'c0\'b4\'c2\'b7\'be\'b6\'d3\'eb\'bb\'ee\'b6\'af
\f0 , Feb 14, 2019.\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0\cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Aminer.cn, AI 2000 ranking (2019 - 2022). {{\NeXTGraphic Attachment.png \width320 \height320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\
}